## LoRA and MoE

the moe routing stats file is from a 1 epoch run that only got up to 58% mean token accuracy I did another run with a more aggressive rate of update with 2 epochs and reached a 75% mean token accuracy but I lost the routing file due to a google collab crash so I dont have it but I presume it was better than what was happening at step 670 in that file since it was 1 adapter hogging up all the tokens in there 
